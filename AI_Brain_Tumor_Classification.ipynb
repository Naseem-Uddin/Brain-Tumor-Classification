{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOidLAUPFYkX7zWji+CQn0y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o5g6L6ueWo2F",
        "outputId": "6f514466-fb47-44d3-be6b-da7e25c75f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.40.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, python-dotenv, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.1 python-dotenv-1.0.1 streamlit-1.40.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit pyngrok python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "metadata": {
        "id": "8Mni2VjMW4pM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_token = userdata.get(\"NGROK_AUTH_KEY\")\n",
        "\n",
        "ngrok.set_auth_token(ngrok_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUe_HCA_XBVT",
        "outputId": "fa784e2e-17d7-4660-d03e-a735a81cdc40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_streamlit():\n",
        "  os.system(\"streamlit run /content/app.py --server.port 8501\")"
      ],
      "metadata": {
        "id": "6ruKhizhXl2k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "output_dir = \"saliency_maps\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def generate_explanation(img_path, model_prediction, confidence):\n",
        "    prompt = f\"\"\"You are an experienced brain surgeon. You are tasked with explaining a saliency map of a brain tumor MRI scan.\n",
        "    The saliency map was generated by a deep learning model that was trained to classify brain tumors\n",
        "    as either glioma, meningioma, pituitary, or no tumor.\n",
        "\n",
        "    The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.\n",
        "\n",
        "    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.\n",
        "\n",
        "    In your response:\n",
        "    - Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted\n",
        "    in light cyan, those are the regions where the model is focusing on.\n",
        "    - Explain possible reasons why the model made the prediction it did.\n",
        "    - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan', we want actual detalied eplanations of what the ML model was focusing on and how the area indicates that there is a case of glioma, or no brain tumor, or etc.\n",
        "    - Keep your explanation to 4 sentences max.\n",
        "    - After your explanation give a couple of next steps that should be taken by the patient. Remember you are a brain surgeon so you should give them advice and statistics on the severity of their tumor and what they can do next. Do NOT give them false hope or no hope, but be honest.\n",
        "\n",
        "    Let's think step by step about this. Verify step by step.\n",
        "    \"\"\"\n",
        "\n",
        "    img = PIL.Image.open(img_path)\n",
        "\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "    response = model.generate_content([prompt, img])\n",
        "\n",
        "    return response.text\n",
        "\n",
        "\n",
        "\n",
        "def generate_saliency_map(model, img_array, class_index, img_size):\n",
        "  with tf.GradientTape() as tape:\n",
        "    img_tensor = tf.convert_to_tensor(img_array)\n",
        "    tape.watch(img_tensor)\n",
        "    predictions = model(img_tensor)\n",
        "    target_class = predictions[:, class_index]\n",
        "\n",
        "  gradients = tape.gradient(target_class, img_tensor)\n",
        "  gradients = tf.math.abs(gradients)\n",
        "  gradients = tf.reduce_max(gradients, axis=-1)\n",
        "  gradients = gradients.numpy().squeeze()\n",
        "\n",
        "  gradients = cv2.resize(gradients, img_size)\n",
        "\n",
        "  center = (gradients.shape[0] // 2, gradients.shape[1] // 2)\n",
        "  radius = min(center[0], center[1])\n",
        "  y, x, = np.ogrid[:gradients.shape[0], :gradients.shape[1]]\n",
        "  mask = (x - center[0])**2 + (y- center[1])**2  <= radius**2\n",
        "\n",
        "  gradients = gradients * mask\n",
        "\n",
        "  brain_gradients = gradients[mask]\n",
        "  if brain_gradients.max() > brain_gradients.min():\n",
        "    brain_gradients = ((brain_gradients - brain_gradients.min()) / ((brain_gradients.max()) - brain_gradients.min()))\n",
        "  gradients[mask] = brain_gradients\n",
        "\n",
        "  threshold = np.percentile(gradients[mask], 80)\n",
        "  gradients[gradients < threshold] = 0\n",
        "\n",
        "  gradients = cv2.GaussianBlur(gradients, (11, 11), 0)\n",
        "\n",
        "  heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)\n",
        "  heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  heatmap = cv2.resize(heatmap, img_size)\n",
        "\n",
        "  original_img = image.img_to_array(img)\n",
        "  superimposed_img = heatmap * 0.7 + original_img * 0.3\n",
        "  superimposed_img = superimposed_img.astype(np.uint8)\n",
        "\n",
        "  img_path = os.path.join(output_dir, uploaded_file.name)\n",
        "  with open(img_path, \"wb\") as f:\n",
        "    f.write(uploaded_file.getbuffer())\n",
        "\n",
        "  saliency_map_path = f\"saliency_maps/{uploaded_file.name}\"\n",
        "\n",
        "  cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "  return superimposed_img\n",
        "\n",
        "def load_xception_model(model_path):\n",
        "  img_shape = (299, 299, 3)\n",
        "  base_model = tf.keras.applications.Xception(\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    input_shape=img_shape,\n",
        "    pooling='max'\n",
        "  )\n",
        "\n",
        "  model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dropout(rate=0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(rate=0.25),\n",
        "    Dense(4, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.build((None,) + img_shape)\n",
        "\n",
        "  model.compile(\n",
        "    Adamax(learning_rate=0.001),\n",
        "    loss='catergorical_crossentropy',\n",
        "    metrics=['accuracy', Precision(), Recall()]\n",
        "  )\n",
        "  model.load_weights(model_path)\n",
        "\n",
        "  return model\n",
        "\n",
        "st.title(\"Brain Tumor Classification\")\n",
        "\n",
        "st.write(\"Upload an image of a brain MRI scan to begin classification process\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image\", type=(\"jpg\", \"jpeg\", \"png\"))\n",
        "\n",
        "if uploaded_file is not None:\n",
        "  selected_model = st.radio(\n",
        "    \"Select Model\",\n",
        "    (\"Transfer Learning - Xception\", \"Custom CNN\")\n",
        "  )\n",
        "\n",
        "  if selected_model == \"Transfer Learning - Xception\":\n",
        "    model = load_xception_model('/content/xception_model.weights.h5')\n",
        "    img_size = (299, 299)\n",
        "  else:\n",
        "    model = load_model('/content/cnn_model.h5')\n",
        "    img_size = (224, 224)\n",
        "\n",
        "  labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
        "  img = image.load_img(uploaded_file, target_size=img_size)\n",
        "  img_array = image.img_to_array(img)\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "  img_array /= 255.0\n",
        "\n",
        "  prediction = model.predict(img_array)\n",
        "\n",
        "  class_index = np.argmax(prediction[0])\n",
        "  result = labels[class_index]\n",
        "\n",
        "  st.write(f\"Predicted Class: {result}\")\n",
        "  st.write(\"Predictions:\")\n",
        "  for label, prob in zip(labels, prediction[0]):\n",
        "    st.write(f\"{label}: {prob:.4f}\")\n",
        "\n",
        "  saliency_map = generate_saliency_map(model, img_array, class_index, img_size)\n",
        "\n",
        "  col1, col2 = st.columns(2)\n",
        "  with col1:\n",
        "    st.image(uploaded_file, caption=\"Uploaded Image\", use_column_width=True)\n",
        "  with col2:\n",
        "    st.image(saliency_map, caption=\"Saliency Map\", use_column_width=True)\n",
        "\n",
        "  st.write(\"## Classification Results\")\n",
        "\n",
        "  result_container = st.container()\n",
        "  result_container = st.container()\n",
        "  some_confidence = (prediction[0][class_index] * 100)\n",
        "  if some_confidence == 100:\n",
        "    font_color = '#00FF00' #Green\n",
        "  if some_confidence > 80 and some_confidence < 100:\n",
        "    font_color = '#0000FF' #Blue\n",
        "  if some_confidence > 75 and some_confidence < 80:\n",
        "    font_color = '#FFFF00' #Yellow\n",
        "  if some_confidence < 75:\n",
        "    font_color = '#FF0000' #Red\n",
        "\n",
        "  if result == 'No Tumor':\n",
        "    text_font_color = '#FFFFFF' #White\n",
        "  else:\n",
        "    text_font_color = '#FF0000' #Red\n",
        "\n",
        "  result_container.markdown(\n",
        "    f\"\"\"\n",
        "    <div style=\"background-color: #000000; color: #ffffff; padding: 30px; border-radius: 15px;\">\n",
        "        <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
        "            <div style=\"flex: 1; text-align: center;\">\n",
        "                <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Prediction</h3>\n",
        "                <p style=\"font-size: 36px; font-weight: 800; color: {text_font_color}; margin: 0;\">\n",
        "                    {result}\n",
        "                </p>\n",
        "            </div>\n",
        "            <div style=\"width: 2px; height: 80px; background-color: #ffffff; margin: 0 20px;\"></div>\n",
        "            <div style=\"flex: 1; text-align: center;\">\n",
        "                <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Confidence</h3>\n",
        "                <p style=\"font-size: 36px; font-weight: 800; color: {font_color}; margin: 0;\">\n",
        "                    {prediction[0][class_index] * 100:.4}%\n",
        "                </p>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        "  )\n",
        "\n",
        "  # Prepare data for Plotly chart\n",
        "  probabilities = prediction[0]\n",
        "  sorted_indices = np.argsort(probabilities)[::-1]\n",
        "  sorted_labels = [labels[i] for i in sorted_indices]\n",
        "  sorted_probabilities = probabilities[sorted_indices]\n",
        "\n",
        "  # Create a Plotly bar chart\n",
        "  fig = go.Figure(go.Bar(\n",
        "    x=sorted_probabilities,\n",
        "    y=sorted_labels,\n",
        "    orientation='h',\n",
        "    marker_color=['red' if label == result else 'blue' for label in sorted_labels]\n",
        "  ))\n",
        "\n",
        "  # Customize the chart layout\n",
        "  fig.update_layout(\n",
        "    title='Probabilities for each class',\n",
        "    xaxis_title='Probability',\n",
        "    yaxis_title='Class',\n",
        "    height=400,\n",
        "    width=600,\n",
        "    yaxis=dict(autorange='reversed')\n",
        "  )\n",
        "\n",
        "  # Add value labels to the bars\n",
        "  for i, prob in enumerate(sorted_probabilities):\n",
        "    fig.add_annotation(\n",
        "        x=prob,\n",
        "        y=i,\n",
        "        text=f'{prob:.4f}',\n",
        "        showarrow=False,\n",
        "        xanchor='left',\n",
        "        xshift=5\n",
        "    )\n",
        "\n",
        "  # Display the Plotly chart\n",
        "  st.plotly_chart(fig)\n",
        "\n",
        "\n",
        "  saliency_map_path = f'saliency_maps/{uploaded_file.name}'\n",
        "  explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])\n",
        "\n",
        "  st.write(\"### Explanation:\")\n",
        "  st.write(explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzCRRb4QXpBg",
        "outputId": "43c09f55-50ac-4f8d-e535-2fc35e220f08"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "active_tunnels = ngrok.get_tunnels()\n",
        "for tunnel in active_tunnels:\n",
        "    print(f\"Killing existing tunnel: {tunnel.public_url}\")\n",
        "    ngrok.disconnect(tunnel.public_url)"
      ],
      "metadata": {
        "id": "nhT4bQeCaTt8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread = Thread(target=run_streamlit)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "jv19knZpZjss"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(addr='8501', proto='http', bind_tls=True)\n",
        "\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIADrU8YYWie",
        "outputId": "c2a9f21c-cb73-4b3b-9cad-59c9a5377d12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://dc59-34-83-227-74.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A7RZrxVH6AzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0YVUa6K3F1E",
        "outputId": "0fd83efe-6cc9-4f4e-f008-000d78f021a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hD0XweCL3Hei"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}